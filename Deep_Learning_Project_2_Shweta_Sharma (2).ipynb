{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Deep Learning Project-2**"
      ],
      "metadata": {
        "id": "24XvjMbMyqPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Submitted by :\n",
        "##Name: Shweta Sharma\n",
        "##UIN: 433003780"
      ],
      "metadata": {
        "id": "kFmwvaVSzGSX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y88s4Gi0FR6M"
      },
      "source": [
        "Project two. Due: 11:59pm (Central Time) on Friday 4/7/2023. (Submit all your code with detailed/clear explanations in a single Jupyter notebook file in Canvas. Email your trained model AS WELL AS its output for the \"testing dataset\" to csce636projects2023@gmail.com with your name and UIN . 105 points)\n",
        "\n",
        "This project is on machine translation for two \"artificial\" languages: an \"Input Language\" and an \"Output Language\". We want to build a model to translate the texts in the \"Input Language\" to texts in the \"Output Language\". For example, a text in the \"Input Language\" can be \"a g b f a f a e a k a j c f b f c d a k a k c e b g a h a k b d b f b f b d c d \" , and its translation to the \"Output Language\" is \"b f c f b f c d a j e f g c e b g a k i j b d b f a k l m b f b d a h ed ee ef a k k eg a k h eh a e ei c d a f ej ek a g d el\".\n",
        "\n",
        "As a training dataset, a list of 5,000 texts in the Input Language are here, and the corresponding list of 5,000 texts in the Output Language are here.  (After downloading them, you can use pickle.load(open(path,'rb')) to open them. They are two lists of strings in Python.)\n",
        "\n",
        "Your task is to design and train a good model, which can take texts in the \"Input language\" as its input, translate them to the corresponding texts in the \"Output Language\" and output them. (Note: the final output of your code should not include extra tokens such as [start] or [end]. So if your model's output includes such extra tokens, you need to write a few more lines of code to remove them.)\n",
        "\n",
        "Your trained model will be evaluated using a testing set (which is shown below, and is similar to the above training set). Its performance will be measured by its \"accuracy for words\", defined as follows. Given a text, a word is a continuous sequence of letters separated by space in the text. (For example, the text \"b f c ej ek d el\" has 7 words: \"b\", \"f\", \"c\", \"ej\", \"ek\", \"d\" and \"el\".) \"Accuracy\" is defined as the fraction of words in the ground-truth text (in the Output Language) that are shown correctly in your model's output. (For example, if the ground-truth text is \"b f c ej ek d el\" and your model's output is \"b c el\", then your result has 1 correct word and 6 mistaken words (since the ground-truth text has 7 words in total). If your model's output is \"b c el ej ek a b c d f g\", then your result has 3 correct words and 4 mistaken words.)\n",
        "\n",
        "You should submit THREE things:\n",
        "\n",
        "**1) Place all your code in a single Jupyter notebook, and submit it in Canvas. You should accompany your code with clear/detailed explanations, so that we can understand the methods you used.**\n",
        "\n",
        "**2) Email your trained model to csce636projects2023@gmail.com. (Please make sure to include your name and UIN in the email.) We need to be able to test your model very easily in Google CoLab by running a simple line of code on our test set (described below). Your model should accept a batch of sentences (not just a single sentence) as input, and output the corresponding batch of \"Output Language\" sentences. You need to specify in your Jupyter notebook what that single line of code is that can do the above.**\n",
        "\n",
        "**3) As the test dataset for this project, a list of 5,000 texts in the Input Language are here. Please run your trained model to get the 5,000  corresponding texts in the Output Language (as a list of 5,000 strings in Python), and email them to csce636projects2023@gmail.com. (You can use pickle.dump(yourList, open(path,'wb')) to save your list in a file, and then attach it to your email.) Please note that we will use your model to verify the above submitted texts, but we will use our own code to compute the accuracy of your model on the test dataset.**\n",
        "\n",
        "Method of grading: your grade for this project will be equal to:\n",
        "\n",
        "(test_accuracy_for_words +  0.05) x 100\n",
        "\n",
        "For example, if your test accuracy is 0.75, then the grade is 80; and if your test accuracy is 0.98, then the grade is 103. However, if the code in your Jupyter notebook is incomplete, the grade will be 0; if the explanations in the Jupyter notebook are not clear, then 5 points will be taken away; and if we need to make any (even simple) modification to your code in order to run it for testing (instead of simply running a single line of code following your instruction), then some points will be taken away (depending on how serious the modification needs to be)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Solution:**"
      ],
      "metadata": {
        "id": "_nlf77hu3Br4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Training Inputs and Outputs using pickle:"
      ],
      "metadata": {
        "id": "QuxI_8Pm3GQ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luh1oZTwFR6P"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "train_input_path=\"/content/DS_5_train_input\"\n",
        "train_output_path=\"/content/DS_5_train_output\"\n",
        "\n",
        "train_inputs=pickle.load(open(train_input_path, 'rb'))\n",
        "train_outputs=pickle.load(open(train_output_path, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wlwvKDNo9gO",
        "outputId": "2d25c272-824e-42ae-b36c-ecdace8476bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rghLYA3pNyk",
        "outputId": "3b86f305-40fc-444f-f529-265fb0acd817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = max(train_inputs, key = len)\n",
        "print(len(res.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ5pdEGnpR9k",
        "outputId": "5ee5afab-2aae-4505-cb04-f3fc067d8763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = max(train_outputs, key = len)\n",
        "print(len(res.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07Y04GaLpvr5",
        "outputId": "da76e56c-2c29-4126-bebb-ed7936ce4050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_inputs[110])\n",
        "print(train_outputs[110])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy6B0WPhnb7Z",
        "outputId": "3842107c-a09c-40d4-cc86-7872d48456fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a f a j a f c f c e a e b g a h a f b e c f a g a f b f b f c d c g a d b e b f \n",
            "c f c e a f d e b g a e g b e c f a f i j b f b f a f l m c d a g ed ee c g a h k ef eg a j f h eh b e b f a d ej ek a f ei el \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This below code checks the unique words present in the vocabulary of Training inputs and Training Outputs which comes out to be 34, which we can use as the vocab_size for our Deep Learning model."
      ],
      "metadata": {
        "id": "fy0ZO44b3UqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab1 = set()\n",
        "for i in range(len(train_inputs)):\n",
        "  for j in train_inputs[i].split():\n",
        "    vocab1.add(j)\n",
        "\n",
        "print(len(vocab1))\n",
        "\n",
        "vocab2=set()\n",
        "for i in range(len(train_outputs)):\n",
        "  for j in train_outputs[i].split():\n",
        "    vocab2.add(j)\n",
        "\n",
        "print(len(vocab2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETXCZ03JykdK",
        "outputId": "37bb6fe6-f9e5-4779-b22f-2544238ec40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_pairs=[]\n",
        "for i in range(len(train_inputs)):\n",
        "  input = train_inputs[i]\n",
        "  output = \"[start] \" + train_outputs[i] + \" [end]\"\n",
        "  text_pairs.append((input,output))"
      ],
      "metadata": {
        "id": "CoG8jvmEqHxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "print(random.choice(text_pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51JaJScUqrGh",
        "outputId": "cac91251-d813-41c2-eef9-8b2f89a53196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('a h a d c f b d a e a k c g a f c e a f a h c f b d a f b d c d c e a g c f c g ', '[start] c f b d a d d e c g c e c f b d b d c d a f k l a h i j m c e a f ed ee a f h ef a k g eg a e eh c f c g a g ej ek a h f ei el  [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code shuffles a list of text_pairs, splits it into training and validation sets, and determines the number of samples for each set.\n",
        "\n",
        "The random.shuffle() function is used to shuffle the text_pairs list randomly. This is often done to ensure that the order of the data does not bias the learning algorithm.\n",
        "\n",
        "The code then calculates the number of validation samples (num_val_samples) as 15% of the total number of text pairs in the list. It also calculates the number of training samples (num_train_samples) as the difference between the total number of text pairs and twice the number of validation samples.\n",
        "\n",
        "The train_pairs variable is then assigned the first num_train_samples pairs in the shuffled list, and val_pairs is assigned the next num_val_samples pairs.\n",
        "\n",
        "These two sets can then be used for training and validation of a machine learning model, respectively."
      ],
      "metadata": {
        "id": "WIeG3lDmIh7x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kdkp15KFR6Q"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fa6LgswFR6R"
      },
      "source": [
        "**Preparing datasets for the translation task**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**target_vectorization  and  source_vectorization:** These lines of code define two TextVectorization layers in TensorFlow. TextVectorization is a layer that takes in text as input and converts it into a sequence of integers, where each integer represents a word in the vocabulary.\n",
        "\n",
        "source_vectorization is used to vectorize the input text data, and target_vectorization is used to vectorize the target text data. The max_tokens parameter specifies the maximum vocabulary size to consider. Any words outside of this vocabulary will be treated as an out-of-vocabulary token.\n",
        "\n",
        "output_mode specifies the output type of the layer, which is set to \"int\" in this case to output integer sequences. output_sequence_length specifies the length of the output sequence, which is set to sequence_length for source_vectorization and sequence_length + 1 for target_vectorization. The standardize parameter is used to apply a custom function to preprocess the text before vectorization.\n",
        "\n",
        "Overall, these layers are useful for preparing text data for use in deep learning models, such as natural language processing (NLP) models.\n"
      ],
      "metadata": {
        "id": "GPDEeqg-sSOo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**make_dataset()** is a Python function that creates a TensorFlow dataset from a list of input-output text pairs.\n",
        "\n",
        "First, the function separates the input and output texts into separate lists. Then, it creates a tf.data.Dataset object using the from_tensor_slices() method, which creates a dataset with one element for each input-output pair.\n",
        "\n",
        "Next, the dataset is batched using the batch() method, which combines individual elements into batches of a specified size (batch_size). The map() method is then used to apply the format_dataset function to each element of the dataset in parallel (num_parallel_calls=4). The format_dataset function likely performs some preprocessing on the input-output pairs, such as tokenization or padding.\n",
        "\n",
        "Finally, the dataset is shuffled (shuffle()), cached (cache()), and prefetched (prefetch()) for optimized performance during training.\n",
        "\n",
        "The returned dataset object can then be used to train a machine learning model, typically a sequence-to-sequence model for tasks such as machine translation or text summarization."
      ],
      "metadata": {
        "id": "_djVxuxnseFI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miXq7KalFR6R"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import string\n",
        "import re\n",
        "\n",
        "vocab_size = 35 #since total vocabulary size is 34\n",
        "sequence_length = 100 #since maximum length currently for output is 95\n",
        "\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(\n",
        "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
        "\n",
        "source_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "target_vectorization = layers.TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_input_texts = [pair[0] for pair in train_pairs]\n",
        "train_output_texts = [pair[1] for pair in train_pairs]\n",
        "source_vectorization.adapt(train_input_texts)\n",
        "target_vectorization.adapt(train_output_texts)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "def format_dataset(inp, out):\n",
        "    inp = source_vectorization(inp)\n",
        "    out = target_vectorization(out)\n",
        "    return ({\n",
        "        \"input\": inp,\n",
        "        \"output\": out[:, :-1],\n",
        "    }, out[:,1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    input_texts, output_texts = zip(*pairs)\n",
        "    input_texts = list(input_texts)\n",
        "    output_texts = list(output_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_texts, output_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB_pCG-DyHZ3",
        "outputId": "f1d8da20-adbd-4357-dd95-4acf5abde829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TakeDataset element_spec=({'input': TensorSpec(shape=(None, 100), dtype=tf.int64, name=None), 'output': TensorSpec(shape=(None, 100), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oiu9hNFUFR6S",
        "outputId": "014aa4ae-be9e-4e52-b18c-3739687b35f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs['input'].shape: (32, 100)\n",
            "inputs['output'].shape: (32, 100)\n",
            "targets.shape: (32, 100)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f\"inputs['input'].shape: {inputs['input'].shape}\")\n",
        "    print(f\"inputs['output'].shape: {inputs['output'].shape}\")\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9DwsYkOFR6T"
      },
      "source": [
        "### Sequence-to-sequence learning with Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps0bbLvAFR6T"
      },
      "source": [
        "#### The Transformer Encoder and Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw9h6FIvFR6U"
      },
      "source": [
        "**The `TransformerEncoder`**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a class definition for a single layer in a transformer encoder. A transformer is a type of neural network architecture commonly used in natural language processing tasks, such as machine translation or text generation.\n",
        "\n",
        "The TransformerEncoder class takes in several parameters that define the layer's properties.\n",
        "\n",
        "embed_dim specifies the dimensionality of the input and output embeddings, which are used to represent words or tokens in the input sequence.\n",
        "\n",
        "dense_dim specifies the number of units in the dense layer of the feedforward network, which is used to process the output of the self-attention mechanism.\n",
        "\n",
        "num_heads specifies the number of heads in the multi-head attention layer. Multi-head attention enables the model to attend to different positions in the input sequence simultaneously, which can improve performance on certain tasks.\n",
        "\n",
        "hidden_layer specifies the number of units in the final hidden layer of the feedforward network.\n",
        "\n",
        "dropout_prob specifies the probability of dropout regularization being applied during training.\n",
        "\n",
        "The call method defines the computation performed by the layer. The layer first applies a multi-head attention mechanism to the input sequence, using layers.MultiHeadAttention. The output of the attention mechanism is then passed through a dense feedforward network with several layers, using layers.Dense. Layer normalization is applied after the attention and dense layers, using layers.LayerNormalization. Finally, the output of the dense feedforward network is added to the original input and normalized again to produce the layer's final output.\n",
        "\n",
        "This class definition can be used to create multiple transformer encoder layers in a larger model, which can be trained on natural language processing tasks.\n"
      ],
      "metadata": {
        "id": "EUJFnW5CtqlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, hidden_layer, dropout_prob, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.dropout_prob = dropout_prob\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dropout(dropout_prob),\n",
        "             layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dropout(dropout_prob),\n",
        "             layers.Dense(hidden_layer, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "            \"hidden_layer\": self.hidden_layer,\n",
        "            \"dropout_prob\": self.dropout_prob,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "MzN_9zd8L10u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The `TransformerDecoder`**"
      ],
      "metadata": {
        "id": "VlVRwPr5vY79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a class definition for a Transformer Decoder in TensorFlow. The Transformer Decoder is a crucial component of a Transformer model, which is a popular deep learning architecture used for natural language processing tasks.\n",
        "\n",
        "The Transformer Decoder takes in encoded inputs and generates a sequence of tokens one by one. The input to the decoder is a concatenation of the encoded input and the previous tokens generated by the decoder, shifted one position to the right (i.e., the decoder tries to predict the next token given the previous tokens).\n",
        "\n",
        "The decoder contains two Multi-Head Attention layers, which attend to the encoded input and the previous tokens, respectively. The output of the Multi-Head Attention layers is concatenated with the previous tokens and passed through a series of dense layers to generate the final output token.\n",
        "\n",
        "The get_causal_attention_mask method returns a mask matrix that prevents the decoder from attending to future tokens during training. This is achieved by setting all the entries in the upper triangular part of the mask to zero."
      ],
      "metadata": {
        "id": "6pHe8OldvHDt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yURkrS6rFR6U"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, hidden_layer, dropout_prob, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.hidden_layer = hidden_layer\n",
        "        self.dropout_prob = dropout_prob\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dropout(dropout_prob),\n",
        "             layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dropout(dropout_prob),\n",
        "             layers.Dense(hidden_layer, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "            \"hidden_layer\": self.hidden_layer,\n",
        "            \"dropout_prob\": self.dropout_prob,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = mask\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B-p4Z70FR6U"
      },
      "source": [
        "#### Putting it all together: A Transformer for machine translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9LuXc8TFR6U"
      },
      "source": [
        "**PositionalEmbedding layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PositionalEmbedding layer is a custom layer in a neural network that adds positional information to the input embeddings. It takes three parameters: sequence_length, input_dim, and output_dim. The sequence_length is the length of the input sequence, the input_dim is the dimensionality of the input embeddings, and the output_dim is the dimensionality of the positional embeddings.\n",
        "\n",
        "In the __init__ method, the layer initializes two Embedding layers: token_embeddings and position_embeddings. The token_embeddings layer learns embeddings for the input tokens, and the position_embeddings layer learns embeddings for the positions of the tokens in the input sequence.\n",
        "\n",
        "In the call method, the layer takes the input tokens and calculates the positions of the tokens. It then embeds the input tokens and the positions separately, and adds the two embeddings together.\n",
        "\n",
        "The compute_mask method returns a mask for the input sequence, which is used to ignore padding tokens in the input sequence during training."
      ],
      "metadata": {
        "id": "Px_AWouuvQbT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAwBtlYuFR6U"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8zeXDiyFR6U"
      },
      "source": [
        "**End-to-end Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are defining a transformer model for sequence to sequence tasks with the encoder-decoder architecture. The input to the model is a pair of sequences, an input sequence, and an output sequence, and the model generates the output sequence given the input sequence.\n",
        "\n",
        "The encoder_inputs and decoder_inputs are input layers that will accept input sequences of integers. The vocab_size specifies the size of the vocabulary for the input sequences. The PositionalEmbedding layer is used to add positional information to the input sequences.\n",
        "\n",
        "The TransformerEncoder layer takes the embedded input sequence and applies the encoder component of the transformer architecture, producing the encoded sequence.\n",
        "\n",
        "The TransformerDecoder layer applies the decoder component of the transformer architecture to the embedded output sequence, using the encoded sequence as context, and generates the output sequence.\n",
        "\n",
        "Finally, the output is passed through a Dense layer with a softmax activation function to get the probability distribution over the vocabulary for each output token.\n",
        "\n",
        "Overall, this model is designed to be used for tasks such as machine translation, where the input sequence is in one language, and the output sequence is in another language.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r7GrpdCFyTiN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLxv-Nm3FR6U"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "dense_dim = 2048\n",
        "num_heads = 8\n",
        "hidden_layer = 512\n",
        "dropout_prob = 0.5\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"input\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "#x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads, hidden_layer, dropout_prob)(x)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"output\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, dense_dim, num_heads, hidden_layer, dropout_prob)(x, encoder_outputs)\n",
        "#x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "W6PRF_NG4VA7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf7t0Qq6FR6V"
      },
      "source": [
        "**Training the sequence-to-sequence Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The compile function specifies the optimizer, loss function, and metrics to be used during training. In this case, you have chosen the rmsprop optimizer, sparse_categorical_crossentropy as the loss function, and accuracy as the evaluation metric.\n",
        "\n",
        "The fit function trains the model using the training data (train_ds), for a specified number of epochs (250 in this case). You have also specified a validation dataset (val_ds) to evaluate the model's performance on during training. Additionally, you have specified a callback function (ModelCheckpoint) that will save the model weights whenever the validation loss improves.\n",
        "\n",
        "Once the model is trained, the weights will be saved to a file named \"transformer_model.keras\" in the current directory."
      ],
      "metadata": {
        "id": "5frGw5lN6AEn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B92zQzHFR6V",
        "outputId": "bb543d44-b5c7-4f48-ad54-573f9de9ee9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "110/110 [==============================] - 25s 142ms/step - loss: 2.7314 - accuracy: 0.2215 - val_loss: 1.7469 - val_accuracy: 0.3498\n",
            "Epoch 2/250\n",
            "110/110 [==============================] - 15s 134ms/step - loss: 1.7563 - accuracy: 0.3415 - val_loss: 1.5134 - val_accuracy: 0.4070\n",
            "Epoch 3/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 1.6200 - accuracy: 0.3760 - val_loss: 1.4570 - val_accuracy: 0.4212\n",
            "Epoch 4/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 1.5366 - accuracy: 0.3969 - val_loss: 1.4674 - val_accuracy: 0.4186\n",
            "Epoch 5/250\n",
            "110/110 [==============================] - 15s 141ms/step - loss: 1.4846 - accuracy: 0.4127 - val_loss: 1.3709 - val_accuracy: 0.4480\n",
            "Epoch 6/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 1.4440 - accuracy: 0.4250 - val_loss: 1.4232 - val_accuracy: 0.4217\n",
            "Epoch 7/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 1.4074 - accuracy: 0.4377 - val_loss: 1.3595 - val_accuracy: 0.4520\n",
            "Epoch 8/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 1.3618 - accuracy: 0.4540 - val_loss: 1.6068 - val_accuracy: 0.3853\n",
            "Epoch 9/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 1.3300 - accuracy: 0.4669 - val_loss: 1.2415 - val_accuracy: 0.4936\n",
            "Epoch 10/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 1.2874 - accuracy: 0.4837 - val_loss: 1.1686 - val_accuracy: 0.5229\n",
            "Epoch 11/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 1.2422 - accuracy: 0.5012 - val_loss: 1.1000 - val_accuracy: 0.5467\n",
            "Epoch 12/250\n",
            "110/110 [==============================] - 15s 137ms/step - loss: 1.2137 - accuracy: 0.5164 - val_loss: 1.3828 - val_accuracy: 0.4561\n",
            "Epoch 13/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 1.1766 - accuracy: 0.5314 - val_loss: 1.0436 - val_accuracy: 0.5687\n",
            "Epoch 14/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 1.1469 - accuracy: 0.5420 - val_loss: 1.1446 - val_accuracy: 0.5482\n",
            "Epoch 15/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 1.1174 - accuracy: 0.5520 - val_loss: 1.0319 - val_accuracy: 0.5741\n",
            "Epoch 16/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 1.0950 - accuracy: 0.5607 - val_loss: 1.1074 - val_accuracy: 0.5612\n",
            "Epoch 17/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 1.0791 - accuracy: 0.5670 - val_loss: 0.9886 - val_accuracy: 0.5877\n",
            "Epoch 18/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 1.0659 - accuracy: 0.5746 - val_loss: 1.0085 - val_accuracy: 0.5833\n",
            "Epoch 19/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 1.0453 - accuracy: 0.5810 - val_loss: 0.9590 - val_accuracy: 0.6065\n",
            "Epoch 20/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 1.0278 - accuracy: 0.5859 - val_loss: 0.9813 - val_accuracy: 0.5987\n",
            "Epoch 21/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 1.0080 - accuracy: 0.5917 - val_loss: 1.0110 - val_accuracy: 0.5859\n",
            "Epoch 22/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.9895 - accuracy: 0.5989 - val_loss: 1.1401 - val_accuracy: 0.5547\n",
            "Epoch 23/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.9767 - accuracy: 0.6052 - val_loss: 0.9030 - val_accuracy: 0.6277\n",
            "Epoch 24/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.9666 - accuracy: 0.6077 - val_loss: 0.8704 - val_accuracy: 0.6338\n",
            "Epoch 25/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.9498 - accuracy: 0.6140 - val_loss: 0.8858 - val_accuracy: 0.6326\n",
            "Epoch 26/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.9408 - accuracy: 0.6175 - val_loss: 1.0763 - val_accuracy: 0.5751\n",
            "Epoch 27/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.9306 - accuracy: 0.6208 - val_loss: 0.8878 - val_accuracy: 0.6298\n",
            "Epoch 28/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.9258 - accuracy: 0.6224 - val_loss: 0.9743 - val_accuracy: 0.5975\n",
            "Epoch 29/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.9015 - accuracy: 0.6302 - val_loss: 0.8863 - val_accuracy: 0.6319\n",
            "Epoch 30/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.8992 - accuracy: 0.6321 - val_loss: 0.8620 - val_accuracy: 0.6372\n",
            "Epoch 31/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.8826 - accuracy: 0.6370 - val_loss: 0.8405 - val_accuracy: 0.6448\n",
            "Epoch 32/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.8783 - accuracy: 0.6381 - val_loss: 0.8599 - val_accuracy: 0.6379\n",
            "Epoch 33/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.8679 - accuracy: 0.6425 - val_loss: 0.9138 - val_accuracy: 0.6229\n",
            "Epoch 34/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.8637 - accuracy: 0.6440 - val_loss: 0.8524 - val_accuracy: 0.6426\n",
            "Epoch 35/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.8602 - accuracy: 0.6461 - val_loss: 0.7978 - val_accuracy: 0.6626\n",
            "Epoch 36/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.8480 - accuracy: 0.6494 - val_loss: 0.7804 - val_accuracy: 0.6678\n",
            "Epoch 37/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.8370 - accuracy: 0.6534 - val_loss: 0.7807 - val_accuracy: 0.6680\n",
            "Epoch 38/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.8394 - accuracy: 0.6532 - val_loss: 0.8089 - val_accuracy: 0.6589\n",
            "Epoch 39/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.8198 - accuracy: 0.6583 - val_loss: 0.9807 - val_accuracy: 0.6078\n",
            "Epoch 40/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.8198 - accuracy: 0.6596 - val_loss: 0.7766 - val_accuracy: 0.6706\n",
            "Epoch 41/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.8128 - accuracy: 0.6614 - val_loss: 0.7712 - val_accuracy: 0.6706\n",
            "Epoch 42/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.8106 - accuracy: 0.6633 - val_loss: 0.7958 - val_accuracy: 0.6649\n",
            "Epoch 43/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.8050 - accuracy: 0.6657 - val_loss: 0.7859 - val_accuracy: 0.6661\n",
            "Epoch 44/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7968 - accuracy: 0.6670 - val_loss: 0.7920 - val_accuracy: 0.6611\n",
            "Epoch 45/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7931 - accuracy: 0.6706 - val_loss: 0.7778 - val_accuracy: 0.6704\n",
            "Epoch 46/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.7825 - accuracy: 0.6730 - val_loss: 0.7467 - val_accuracy: 0.6794\n",
            "Epoch 47/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7823 - accuracy: 0.6727 - val_loss: 0.8870 - val_accuracy: 0.6378\n",
            "Epoch 48/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7711 - accuracy: 0.6755 - val_loss: 0.7792 - val_accuracy: 0.6741\n",
            "Epoch 49/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7752 - accuracy: 0.6764 - val_loss: 0.8183 - val_accuracy: 0.6607\n",
            "Epoch 50/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7647 - accuracy: 0.6793 - val_loss: 0.7503 - val_accuracy: 0.6806\n",
            "Epoch 51/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7649 - accuracy: 0.6798 - val_loss: 0.9096 - val_accuracy: 0.6310\n",
            "Epoch 52/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7536 - accuracy: 0.6835 - val_loss: 0.8226 - val_accuracy: 0.6612\n",
            "Epoch 53/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.7541 - accuracy: 0.6839 - val_loss: 0.7374 - val_accuracy: 0.6846\n",
            "Epoch 54/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.7469 - accuracy: 0.6862 - val_loss: 0.7223 - val_accuracy: 0.6891\n",
            "Epoch 55/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.7434 - accuracy: 0.6872 - val_loss: 0.7129 - val_accuracy: 0.6932\n",
            "Epoch 56/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.7391 - accuracy: 0.6879 - val_loss: 0.7388 - val_accuracy: 0.6840\n",
            "Epoch 57/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.7341 - accuracy: 0.6907 - val_loss: 0.7245 - val_accuracy: 0.6898\n",
            "Epoch 58/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7331 - accuracy: 0.6914 - val_loss: 0.7282 - val_accuracy: 0.6878\n",
            "Epoch 59/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.7219 - accuracy: 0.6941 - val_loss: 0.7438 - val_accuracy: 0.6838\n",
            "Epoch 60/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7219 - accuracy: 0.6960 - val_loss: 0.7207 - val_accuracy: 0.6917\n",
            "Epoch 61/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7189 - accuracy: 0.6966 - val_loss: 0.7184 - val_accuracy: 0.6909\n",
            "Epoch 62/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7118 - accuracy: 0.6985 - val_loss: 0.7194 - val_accuracy: 0.6941\n",
            "Epoch 63/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.7183 - accuracy: 0.6970 - val_loss: 0.7919 - val_accuracy: 0.6737\n",
            "Epoch 64/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.7071 - accuracy: 0.7017 - val_loss: 0.7101 - val_accuracy: 0.6959\n",
            "Epoch 65/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.6982 - accuracy: 0.7047 - val_loss: 0.8462 - val_accuracy: 0.6601\n",
            "Epoch 66/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.6975 - accuracy: 0.7048 - val_loss: 0.7086 - val_accuracy: 0.6976\n",
            "Epoch 67/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.6898 - accuracy: 0.7088 - val_loss: 0.7033 - val_accuracy: 0.7008\n",
            "Epoch 68/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.6847 - accuracy: 0.7111 - val_loss: 0.7413 - val_accuracy: 0.6890\n",
            "Epoch 69/250\n",
            "110/110 [==============================] - 15s 137ms/step - loss: 0.6831 - accuracy: 0.7131 - val_loss: 0.7228 - val_accuracy: 0.6964\n",
            "Epoch 70/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.6779 - accuracy: 0.7154 - val_loss: 0.7063 - val_accuracy: 0.7036\n",
            "Epoch 71/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.6746 - accuracy: 0.7178 - val_loss: 0.7309 - val_accuracy: 0.6960\n",
            "Epoch 72/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.6689 - accuracy: 0.7203 - val_loss: 0.7208 - val_accuracy: 0.7010\n",
            "Epoch 73/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.6635 - accuracy: 0.7218 - val_loss: 0.6811 - val_accuracy: 0.7137\n",
            "Epoch 74/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.6627 - accuracy: 0.7244 - val_loss: 0.6776 - val_accuracy: 0.7156\n",
            "Epoch 75/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.6471 - accuracy: 0.7290 - val_loss: 0.7210 - val_accuracy: 0.7012\n",
            "Epoch 76/250\n",
            "110/110 [==============================] - 15s 141ms/step - loss: 0.6412 - accuracy: 0.7327 - val_loss: 0.6752 - val_accuracy: 0.7178\n",
            "Epoch 77/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.6359 - accuracy: 0.7345 - val_loss: 0.6815 - val_accuracy: 0.7224\n",
            "Epoch 78/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.6307 - accuracy: 0.7364 - val_loss: 0.6403 - val_accuracy: 0.7311\n",
            "Epoch 79/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.6305 - accuracy: 0.7375 - val_loss: 0.6635 - val_accuracy: 0.7253\n",
            "Epoch 80/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.6187 - accuracy: 0.7420 - val_loss: 0.6610 - val_accuracy: 0.7281\n",
            "Epoch 81/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.6225 - accuracy: 0.7410 - val_loss: 0.6823 - val_accuracy: 0.7161\n",
            "Epoch 82/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.6100 - accuracy: 0.7457 - val_loss: 0.6585 - val_accuracy: 0.7291\n",
            "Epoch 83/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.6084 - accuracy: 0.7463 - val_loss: 0.6430 - val_accuracy: 0.7320\n",
            "Epoch 84/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5970 - accuracy: 0.7505 - val_loss: 0.6662 - val_accuracy: 0.7249\n",
            "Epoch 85/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.5927 - accuracy: 0.7532 - val_loss: 0.6186 - val_accuracy: 0.7374\n",
            "Epoch 86/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.5872 - accuracy: 0.7543 - val_loss: 0.6065 - val_accuracy: 0.7477\n",
            "Epoch 87/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5778 - accuracy: 0.7592 - val_loss: 0.6197 - val_accuracy: 0.7390\n",
            "Epoch 88/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5735 - accuracy: 0.7609 - val_loss: 0.6159 - val_accuracy: 0.7410\n",
            "Epoch 89/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5649 - accuracy: 0.7637 - val_loss: 0.6121 - val_accuracy: 0.7455\n",
            "Epoch 90/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.5580 - accuracy: 0.7673 - val_loss: 0.5885 - val_accuracy: 0.7529\n",
            "Epoch 91/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.5514 - accuracy: 0.7701 - val_loss: 0.5726 - val_accuracy: 0.7608\n",
            "Epoch 92/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5406 - accuracy: 0.7746 - val_loss: 0.6956 - val_accuracy: 0.7235\n",
            "Epoch 93/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5368 - accuracy: 0.7770 - val_loss: 0.6118 - val_accuracy: 0.7497\n",
            "Epoch 94/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.5354 - accuracy: 0.7776 - val_loss: 0.5473 - val_accuracy: 0.7694\n",
            "Epoch 95/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5220 - accuracy: 0.7818 - val_loss: 0.6054 - val_accuracy: 0.7517\n",
            "Epoch 96/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5141 - accuracy: 0.7845 - val_loss: 0.5850 - val_accuracy: 0.7595\n",
            "Epoch 97/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5109 - accuracy: 0.7858 - val_loss: 0.5580 - val_accuracy: 0.7694\n",
            "Epoch 98/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.5017 - accuracy: 0.7895 - val_loss: 0.5493 - val_accuracy: 0.7742\n",
            "Epoch 99/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.4989 - accuracy: 0.7902 - val_loss: 0.5662 - val_accuracy: 0.7670\n",
            "Epoch 100/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.4932 - accuracy: 0.7938 - val_loss: 0.5957 - val_accuracy: 0.7566\n",
            "Epoch 101/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.4874 - accuracy: 0.7957 - val_loss: 0.5211 - val_accuracy: 0.7818\n",
            "Epoch 102/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.4813 - accuracy: 0.7981 - val_loss: 0.5395 - val_accuracy: 0.7789\n",
            "Epoch 103/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.4792 - accuracy: 0.7994 - val_loss: 0.5264 - val_accuracy: 0.7791\n",
            "Epoch 104/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.4710 - accuracy: 0.8030 - val_loss: 0.5409 - val_accuracy: 0.7775\n",
            "Epoch 105/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.4704 - accuracy: 0.8041 - val_loss: 0.5406 - val_accuracy: 0.7780\n",
            "Epoch 106/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.4590 - accuracy: 0.8071 - val_loss: 0.5201 - val_accuracy: 0.7866\n",
            "Epoch 107/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.4574 - accuracy: 0.8093 - val_loss: 0.5117 - val_accuracy: 0.7908\n",
            "Epoch 108/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.4504 - accuracy: 0.8102 - val_loss: 0.5206 - val_accuracy: 0.7859\n",
            "Epoch 109/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.4453 - accuracy: 0.8136 - val_loss: 0.5203 - val_accuracy: 0.7874\n",
            "Epoch 110/250\n",
            "110/110 [==============================] - 15s 137ms/step - loss: 0.4408 - accuracy: 0.8159 - val_loss: 0.5202 - val_accuracy: 0.7898\n",
            "Epoch 111/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.4392 - accuracy: 0.8162 - val_loss: 0.4987 - val_accuracy: 0.7934\n",
            "Epoch 112/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.4329 - accuracy: 0.8188 - val_loss: 0.5000 - val_accuracy: 0.7984\n",
            "Epoch 113/250\n",
            "110/110 [==============================] - 15s 134ms/step - loss: 0.4262 - accuracy: 0.8207 - val_loss: 0.5208 - val_accuracy: 0.7908\n",
            "Epoch 114/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.4250 - accuracy: 0.8234 - val_loss: 0.4899 - val_accuracy: 0.7970\n",
            "Epoch 115/250\n",
            "110/110 [==============================] - 15s 141ms/step - loss: 0.4167 - accuracy: 0.8257 - val_loss: 0.4832 - val_accuracy: 0.8048\n",
            "Epoch 116/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.4137 - accuracy: 0.8274 - val_loss: 0.5397 - val_accuracy: 0.7904\n",
            "Epoch 117/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.4113 - accuracy: 0.8289 - val_loss: 0.4952 - val_accuracy: 0.8002\n",
            "Epoch 118/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.4040 - accuracy: 0.8303 - val_loss: 0.4943 - val_accuracy: 0.7988\n",
            "Epoch 119/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.4020 - accuracy: 0.8327 - val_loss: 0.4534 - val_accuracy: 0.8129\n",
            "Epoch 120/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3921 - accuracy: 0.8363 - val_loss: 0.4666 - val_accuracy: 0.8095\n",
            "Epoch 121/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3924 - accuracy: 0.8374 - val_loss: 0.4738 - val_accuracy: 0.8082\n",
            "Epoch 122/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3854 - accuracy: 0.8390 - val_loss: 0.4745 - val_accuracy: 0.8100\n",
            "Epoch 123/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3796 - accuracy: 0.8422 - val_loss: 0.4602 - val_accuracy: 0.8155\n",
            "Epoch 124/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3762 - accuracy: 0.8436 - val_loss: 0.4887 - val_accuracy: 0.8016\n",
            "Epoch 125/250\n",
            "110/110 [==============================] - 15s 138ms/step - loss: 0.3698 - accuracy: 0.8463 - val_loss: 0.4494 - val_accuracy: 0.8218\n",
            "Epoch 126/250\n",
            "110/110 [==============================] - 15s 137ms/step - loss: 0.3683 - accuracy: 0.8477 - val_loss: 0.4495 - val_accuracy: 0.8219\n",
            "Epoch 127/250\n",
            "110/110 [==============================] - 15s 141ms/step - loss: 0.3621 - accuracy: 0.8488 - val_loss: 0.4380 - val_accuracy: 0.8249\n",
            "Epoch 128/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.3591 - accuracy: 0.8509 - val_loss: 0.4377 - val_accuracy: 0.8236\n",
            "Epoch 129/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.3526 - accuracy: 0.8532 - val_loss: 0.4200 - val_accuracy: 0.8317\n",
            "Epoch 130/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3483 - accuracy: 0.8552 - val_loss: 0.4335 - val_accuracy: 0.8251\n",
            "Epoch 131/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3403 - accuracy: 0.8588 - val_loss: 0.4566 - val_accuracy: 0.8222\n",
            "Epoch 132/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.3434 - accuracy: 0.8587 - val_loss: 0.4436 - val_accuracy: 0.8239\n",
            "Epoch 133/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3359 - accuracy: 0.8614 - val_loss: 0.4370 - val_accuracy: 0.8276\n",
            "Epoch 134/250\n",
            "110/110 [==============================] - 15s 140ms/step - loss: 0.3301 - accuracy: 0.8634 - val_loss: 0.4195 - val_accuracy: 0.8312\n",
            "Epoch 135/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.3248 - accuracy: 0.8655 - val_loss: 0.4384 - val_accuracy: 0.8295\n",
            "Epoch 136/250\n",
            "110/110 [==============================] - 15s 138ms/step - loss: 0.3272 - accuracy: 0.8661 - val_loss: 0.3963 - val_accuracy: 0.8409\n",
            "Epoch 137/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.3184 - accuracy: 0.8695 - val_loss: 0.4085 - val_accuracy: 0.8384\n",
            "Epoch 138/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.3152 - accuracy: 0.8704 - val_loss: 0.3943 - val_accuracy: 0.8439\n",
            "Epoch 139/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.3088 - accuracy: 0.8726 - val_loss: 0.4007 - val_accuracy: 0.8412\n",
            "Epoch 140/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.3068 - accuracy: 0.8739 - val_loss: 0.3942 - val_accuracy: 0.8432\n",
            "Epoch 141/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2995 - accuracy: 0.8774 - val_loss: 0.4515 - val_accuracy: 0.8295\n",
            "Epoch 142/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2977 - accuracy: 0.8776 - val_loss: 0.4264 - val_accuracy: 0.8410\n",
            "Epoch 143/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2934 - accuracy: 0.8799 - val_loss: 0.4163 - val_accuracy: 0.8402\n",
            "Epoch 144/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2900 - accuracy: 0.8821 - val_loss: 0.4276 - val_accuracy: 0.8380\n",
            "Epoch 145/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2866 - accuracy: 0.8827 - val_loss: 0.4070 - val_accuracy: 0.8425\n",
            "Epoch 146/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.2838 - accuracy: 0.8847 - val_loss: 0.3711 - val_accuracy: 0.8549\n",
            "Epoch 147/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2787 - accuracy: 0.8859 - val_loss: 0.4583 - val_accuracy: 0.8312\n",
            "Epoch 148/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2792 - accuracy: 0.8865 - val_loss: 0.4008 - val_accuracy: 0.8454\n",
            "Epoch 149/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2746 - accuracy: 0.8884 - val_loss: 0.4157 - val_accuracy: 0.8438\n",
            "Epoch 150/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.2713 - accuracy: 0.8896 - val_loss: 0.3644 - val_accuracy: 0.8568\n",
            "Epoch 151/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2665 - accuracy: 0.8909 - val_loss: 0.4020 - val_accuracy: 0.8529\n",
            "Epoch 152/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2637 - accuracy: 0.8931 - val_loss: 0.3739 - val_accuracy: 0.8560\n",
            "Epoch 153/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2631 - accuracy: 0.8940 - val_loss: 0.3812 - val_accuracy: 0.8541\n",
            "Epoch 154/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2586 - accuracy: 0.8947 - val_loss: 0.3705 - val_accuracy: 0.8582\n",
            "Epoch 155/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.2530 - accuracy: 0.8975 - val_loss: 0.3628 - val_accuracy: 0.8630\n",
            "Epoch 156/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2524 - accuracy: 0.8977 - val_loss: 0.4117 - val_accuracy: 0.8472\n",
            "Epoch 157/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2470 - accuracy: 0.8994 - val_loss: 0.3713 - val_accuracy: 0.8607\n",
            "Epoch 158/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2449 - accuracy: 0.9012 - val_loss: 0.4119 - val_accuracy: 0.8490\n",
            "Epoch 159/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2428 - accuracy: 0.9022 - val_loss: 0.4702 - val_accuracy: 0.8333\n",
            "Epoch 160/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.2453 - accuracy: 0.9013 - val_loss: 0.3563 - val_accuracy: 0.8651\n",
            "Epoch 161/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2359 - accuracy: 0.9045 - val_loss: 0.3577 - val_accuracy: 0.8670\n",
            "Epoch 162/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2354 - accuracy: 0.9048 - val_loss: 0.3677 - val_accuracy: 0.8614\n",
            "Epoch 163/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.2329 - accuracy: 0.9057 - val_loss: 0.3465 - val_accuracy: 0.8683\n",
            "Epoch 164/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2335 - accuracy: 0.9060 - val_loss: 0.3818 - val_accuracy: 0.8585\n",
            "Epoch 165/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2298 - accuracy: 0.9071 - val_loss: 0.3833 - val_accuracy: 0.8620\n",
            "Epoch 166/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2252 - accuracy: 0.9097 - val_loss: 0.3876 - val_accuracy: 0.8615\n",
            "Epoch 167/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2287 - accuracy: 0.9089 - val_loss: 0.3697 - val_accuracy: 0.8657\n",
            "Epoch 168/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.2315 - accuracy: 0.9070 - val_loss: 0.3451 - val_accuracy: 0.8702\n",
            "Epoch 169/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2251 - accuracy: 0.9097 - val_loss: 0.4385 - val_accuracy: 0.8406\n",
            "Epoch 170/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.2209 - accuracy: 0.9122 - val_loss: 0.3416 - val_accuracy: 0.8742\n",
            "Epoch 171/250\n",
            "110/110 [==============================] - 15s 138ms/step - loss: 0.2226 - accuracy: 0.9121 - val_loss: 0.3303 - val_accuracy: 0.8755\n",
            "Epoch 172/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2161 - accuracy: 0.9139 - val_loss: 0.3515 - val_accuracy: 0.8703\n",
            "Epoch 173/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.2167 - accuracy: 0.9143 - val_loss: 0.3283 - val_accuracy: 0.8781\n",
            "Epoch 174/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2129 - accuracy: 0.9157 - val_loss: 0.3513 - val_accuracy: 0.8724\n",
            "Epoch 175/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2100 - accuracy: 0.9163 - val_loss: 0.3498 - val_accuracy: 0.8717\n",
            "Epoch 176/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2074 - accuracy: 0.9180 - val_loss: 0.3954 - val_accuracy: 0.8583\n",
            "Epoch 177/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2035 - accuracy: 0.9184 - val_loss: 0.3343 - val_accuracy: 0.8785\n",
            "Epoch 178/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.2032 - accuracy: 0.9196 - val_loss: 0.3657 - val_accuracy: 0.8697\n",
            "Epoch 179/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.2002 - accuracy: 0.9211 - val_loss: 0.3687 - val_accuracy: 0.8674\n",
            "Epoch 180/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1997 - accuracy: 0.9203 - val_loss: 0.3547 - val_accuracy: 0.8762\n",
            "Epoch 181/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1973 - accuracy: 0.9218 - val_loss: 0.3694 - val_accuracy: 0.8714\n",
            "Epoch 182/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1948 - accuracy: 0.9231 - val_loss: 0.3583 - val_accuracy: 0.8761\n",
            "Epoch 183/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1934 - accuracy: 0.9240 - val_loss: 0.4163 - val_accuracy: 0.8561\n",
            "Epoch 184/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1924 - accuracy: 0.9240 - val_loss: 0.3444 - val_accuracy: 0.8778\n",
            "Epoch 185/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1880 - accuracy: 0.9262 - val_loss: 0.3789 - val_accuracy: 0.8698\n",
            "Epoch 186/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1863 - accuracy: 0.9265 - val_loss: 0.3362 - val_accuracy: 0.8810\n",
            "Epoch 187/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1868 - accuracy: 0.9273 - val_loss: 0.3377 - val_accuracy: 0.8804\n",
            "Epoch 188/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.1821 - accuracy: 0.9286 - val_loss: 0.3266 - val_accuracy: 0.8862\n",
            "Epoch 189/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1820 - accuracy: 0.9290 - val_loss: 0.3465 - val_accuracy: 0.8798\n",
            "Epoch 190/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1782 - accuracy: 0.9299 - val_loss: 0.3332 - val_accuracy: 0.8837\n",
            "Epoch 191/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1798 - accuracy: 0.9296 - val_loss: 0.3279 - val_accuracy: 0.8827\n",
            "Epoch 192/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1742 - accuracy: 0.9321 - val_loss: 0.3339 - val_accuracy: 0.8830\n",
            "Epoch 193/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1735 - accuracy: 0.9326 - val_loss: 0.3333 - val_accuracy: 0.8852\n",
            "Epoch 194/250\n",
            "110/110 [==============================] - 15s 138ms/step - loss: 0.1734 - accuracy: 0.9324 - val_loss: 0.3173 - val_accuracy: 0.8877\n",
            "Epoch 195/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1688 - accuracy: 0.9343 - val_loss: 0.3582 - val_accuracy: 0.8773\n",
            "Epoch 196/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1705 - accuracy: 0.9343 - val_loss: 0.4183 - val_accuracy: 0.8637\n",
            "Epoch 197/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1765 - accuracy: 0.9325 - val_loss: 0.3420 - val_accuracy: 0.8811\n",
            "Epoch 198/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1677 - accuracy: 0.9347 - val_loss: 0.3280 - val_accuracy: 0.8855\n",
            "Epoch 199/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1642 - accuracy: 0.9359 - val_loss: 0.3270 - val_accuracy: 0.8887\n",
            "Epoch 200/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1636 - accuracy: 0.9362 - val_loss: 0.3395 - val_accuracy: 0.8835\n",
            "Epoch 201/250\n",
            "110/110 [==============================] - 15s 134ms/step - loss: 0.1586 - accuracy: 0.9382 - val_loss: 0.3896 - val_accuracy: 0.8725\n",
            "Epoch 202/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1603 - accuracy: 0.9381 - val_loss: 0.3373 - val_accuracy: 0.8879\n",
            "Epoch 203/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1607 - accuracy: 0.9380 - val_loss: 0.3376 - val_accuracy: 0.8864\n",
            "Epoch 204/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1572 - accuracy: 0.9392 - val_loss: 0.3275 - val_accuracy: 0.8904\n",
            "Epoch 205/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1575 - accuracy: 0.9388 - val_loss: 0.3273 - val_accuracy: 0.8862\n",
            "Epoch 206/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1512 - accuracy: 0.9412 - val_loss: 0.4473 - val_accuracy: 0.8600\n",
            "Epoch 207/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1519 - accuracy: 0.9412 - val_loss: 0.3618 - val_accuracy: 0.8838\n",
            "Epoch 208/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1483 - accuracy: 0.9423 - val_loss: 0.3320 - val_accuracy: 0.8889\n",
            "Epoch 209/250\n",
            "110/110 [==============================] - 15s 137ms/step - loss: 0.1496 - accuracy: 0.9421 - val_loss: 0.4122 - val_accuracy: 0.8693\n",
            "Epoch 210/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1485 - accuracy: 0.9431 - val_loss: 0.3376 - val_accuracy: 0.8877\n",
            "Epoch 211/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1439 - accuracy: 0.9445 - val_loss: 0.3769 - val_accuracy: 0.8829\n",
            "Epoch 212/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1471 - accuracy: 0.9437 - val_loss: 0.3302 - val_accuracy: 0.8890\n",
            "Epoch 213/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1428 - accuracy: 0.9451 - val_loss: 0.3465 - val_accuracy: 0.8870\n",
            "Epoch 214/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1436 - accuracy: 0.9453 - val_loss: 0.3259 - val_accuracy: 0.8931\n",
            "Epoch 215/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1435 - accuracy: 0.9453 - val_loss: 0.3199 - val_accuracy: 0.8938\n",
            "Epoch 216/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1421 - accuracy: 0.9463 - val_loss: 0.3212 - val_accuracy: 0.8946\n",
            "Epoch 217/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1397 - accuracy: 0.9470 - val_loss: 0.3348 - val_accuracy: 0.8907\n",
            "Epoch 218/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1392 - accuracy: 0.9474 - val_loss: 0.3850 - val_accuracy: 0.8798\n",
            "Epoch 219/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1400 - accuracy: 0.9467 - val_loss: 0.3213 - val_accuracy: 0.8932\n",
            "Epoch 220/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1365 - accuracy: 0.9482 - val_loss: 0.4095 - val_accuracy: 0.8708\n",
            "Epoch 221/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1344 - accuracy: 0.9486 - val_loss: 0.3209 - val_accuracy: 0.8978\n",
            "Epoch 222/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1363 - accuracy: 0.9486 - val_loss: 0.3221 - val_accuracy: 0.8971\n",
            "Epoch 223/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1342 - accuracy: 0.9498 - val_loss: 0.3334 - val_accuracy: 0.8950\n",
            "Epoch 224/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1344 - accuracy: 0.9494 - val_loss: 0.3259 - val_accuracy: 0.8953\n",
            "Epoch 225/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1271 - accuracy: 0.9516 - val_loss: 0.3633 - val_accuracy: 0.8876\n",
            "Epoch 226/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1279 - accuracy: 0.9515 - val_loss: 0.3588 - val_accuracy: 0.8896\n",
            "Epoch 227/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1295 - accuracy: 0.9516 - val_loss: 0.3881 - val_accuracy: 0.8786\n",
            "Epoch 228/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1284 - accuracy: 0.9515 - val_loss: 0.3469 - val_accuracy: 0.8910\n",
            "Epoch 229/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1262 - accuracy: 0.9527 - val_loss: 0.3232 - val_accuracy: 0.8968\n",
            "Epoch 230/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1299 - accuracy: 0.9525 - val_loss: 0.3328 - val_accuracy: 0.8964\n",
            "Epoch 231/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1221 - accuracy: 0.9541 - val_loss: 0.3354 - val_accuracy: 0.8952\n",
            "Epoch 232/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1220 - accuracy: 0.9543 - val_loss: 0.3305 - val_accuracy: 0.8992\n",
            "Epoch 233/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1187 - accuracy: 0.9550 - val_loss: 0.3673 - val_accuracy: 0.8919\n",
            "Epoch 234/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1211 - accuracy: 0.9547 - val_loss: 0.3367 - val_accuracy: 0.8933\n",
            "Epoch 235/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1192 - accuracy: 0.9552 - val_loss: 0.3277 - val_accuracy: 0.8977\n",
            "Epoch 236/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1190 - accuracy: 0.9555 - val_loss: 0.3258 - val_accuracy: 0.9012\n",
            "Epoch 237/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1180 - accuracy: 0.9566 - val_loss: 0.3417 - val_accuracy: 0.8942\n",
            "Epoch 238/250\n",
            "110/110 [==============================] - 15s 136ms/step - loss: 0.1156 - accuracy: 0.9565 - val_loss: 0.3644 - val_accuracy: 0.8911\n",
            "Epoch 239/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1142 - accuracy: 0.9579 - val_loss: 0.3328 - val_accuracy: 0.8962\n",
            "Epoch 240/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1150 - accuracy: 0.9571 - val_loss: 0.3221 - val_accuracy: 0.8999\n",
            "Epoch 241/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1134 - accuracy: 0.9576 - val_loss: 0.3215 - val_accuracy: 0.9009\n",
            "Epoch 242/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1119 - accuracy: 0.9587 - val_loss: 0.3174 - val_accuracy: 0.8989\n",
            "Epoch 243/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1110 - accuracy: 0.9583 - val_loss: 0.3191 - val_accuracy: 0.9001\n",
            "Epoch 244/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.1101 - accuracy: 0.9590 - val_loss: 0.3157 - val_accuracy: 0.9019\n",
            "Epoch 245/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1075 - accuracy: 0.9596 - val_loss: 0.3424 - val_accuracy: 0.8955\n",
            "Epoch 246/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.1081 - accuracy: 0.9598 - val_loss: 0.3137 - val_accuracy: 0.9044\n",
            "Epoch 247/250\n",
            "110/110 [==============================] - 15s 139ms/step - loss: 0.1100 - accuracy: 0.9590 - val_loss: 0.3094 - val_accuracy: 0.9040\n",
            "Epoch 248/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1036 - accuracy: 0.9621 - val_loss: 0.3360 - val_accuracy: 0.9011\n",
            "Epoch 249/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1082 - accuracy: 0.9606 - val_loss: 0.3178 - val_accuracy: 0.9036\n",
            "Epoch 250/250\n",
            "110/110 [==============================] - 15s 135ms/step - loss: 0.1037 - accuracy: 0.9618 - val_loss: 0.3814 - val_accuracy: 0.8924\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4918736490>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"transformer_model.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "transformer.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "transformer.fit(train_ds, epochs=250, validation_data=val_ds, callbacks=callbacks) #epochs=220"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnOhrjRmFR6V"
      },
      "source": [
        "**Translating new sentences with our Transformer model**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a custom objects dictionary containing the PositionalEmbedding, TransformerEncoder, and TransformerDecoder layers used in a previously trained Keras model saved in the file \"transformer_model.keras\". It then loads the model from memory using the keras.models.load_model() method with the custom_object_scope() function to ensure that the custom objects are properly reconstructed.\n",
        "\n",
        "Note that this assumes that the necessary modules and data have been previously loaded into memory, and that the \"transformer_model.keras\" file is in the current working directory."
      ],
      "metadata": {
        "id": "8P5dpg466PCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from keras.utils import custom_object_scope\n",
        "\n",
        "\n",
        "# Define the custom objects dictionary\n",
        "custom_objects = {'PositionalEmbedding': PositionalEmbedding, 'TransformerEncoder': TransformerEncoder, 'TransformerDecoder': TransformerDecoder}\n",
        "\n",
        "# Load the model using custom_object_scope\n",
        "with custom_object_scope(custom_objects):\n",
        "    model_from_memory = keras.models.load_model(\"transformer_model.keras\")"
      ],
      "metadata": {
        "id": "IVWdJOK33Ce0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The decode_sequence function takes an input sentence in the source language as a string and returns the corresponding translated sentence in the target language.\n",
        "\n",
        "Here is how the function works:\n",
        "\n",
        "*  Tokenize the input sentence using the source_vectorization object.\n",
        "* Initialize the decoded sentence with the [start] token.\n",
        "*Loop over the possible target tokens up to the maximum length of the decoded sentence.\n",
        "*Tokenize the current decoded sentence using the target_vectorization object.\n",
        "*Feed the tokenized input sentence and tokenized decoded sentence into the model_from_memory model to get the predictions for the next target token.\n",
        "*Select the target token with the highest probability from the predictions.\n",
        "*Add the selected target token to the decoded sentence.\n",
        "If the selected target token is the [end] token, stop looping and return the decoded sentence.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lk3YlKlG9OCF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3AqvBOKFR6V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "fd5d3f44-9f60-4b0b-99b8-4610a267948e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ecc8e20b8f76>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#change it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0minput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mtest_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-ecc8e20b8f76>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(input_sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m         tokenized_target_sentence = target_vectorization(\n\u001b[1;32m     14\u001b[0m             [decoded_sentence])[:, :-1]\n\u001b[0;32m---> 15\u001b[0;31m         predictions = model_from_memory(\n\u001b[0m\u001b[1;32m     16\u001b[0m             [tokenized_input_sentence, tokenized_target_sentence])\n\u001b[1;32m     17\u001b[0m         \u001b[0msampled_token_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \"\"\"\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-7156dd3b5a2a>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, encoder_outputs, mask)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mpadding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         attention_output_1 = self.attention_1(\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                 ):\n\u001b[0;32m-> 1145\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/layers/attention/multi_head_attention.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, value, key, attention_mask, return_attention_scores, training, use_causal_mask)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         attention_output, attention_scores = self._compute_attention(\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/layers/attention/multi_head_attention.py\u001b[0m in \u001b[0;36m_compute_attention\u001b[0;34m(self, query, key, value, attention_mask, training)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;31m# `context_layer` = [B, T, N, H]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         attention_output = tf.einsum(\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_equation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_scores_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0;34m-\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mare\u001b[0m \u001b[0minconsistent\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m   \"\"\"\n\u001b[0;32m--> 762\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_einsum_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36m_einsum_v2\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1197\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mellipsis_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0mresolved_equation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolved_equation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mellipsis_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_linalg_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolved_equation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;31m# Send fully specified shapes to opt_einsum, since it cannot handle unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(inputs, equation, name)\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   1083\u001b[0m         _ctx, \"Einsum\", name, inputs, \"equation\", equation)\n\u001b[1;32m   1084\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "spa_vocab = target_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 100\n",
        "\n",
        "test_input_path=\"/content/DS_5_test_input\"\n",
        "test_inputs=pickle.load(open(test_input_path, 'rb'))\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = target_vectorization(\n",
        "            [decoded_sentence])[:, :-1]\n",
        "        predictions = model_from_memory(\n",
        "            [tokenized_input_sentence, tokenized_target_sentence])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "test_outputs = []\n",
        "for i in range(len(test_inputs)): #change it\n",
        "    input_sentence = test_inputs[i]\n",
        "    output = decode_sequence(input_sentence)\n",
        "    output = output[8:-6]\n",
        "    test_outputs.append(output)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej0urxM4ic0g",
        "outputId": "87609b74-8b27-47be-f2ae-3c7c7c561ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_output_path=\"/content/DS_5_test_output\"\n",
        "pickle.dump(test_outputs, open(test_output_path,'wb'))"
      ],
      "metadata": {
        "id": "-sUpC9t7CDt-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}